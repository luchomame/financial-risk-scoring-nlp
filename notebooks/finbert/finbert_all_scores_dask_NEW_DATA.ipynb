{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to extracting all labels \n",
    "https://datascience.stackexchange.com/questions/112438/how-to-get-all-3-labels-sentiment-from-finbert-instead-of-the-most-likely-label\n",
    "\n",
    "essentially, us the AutoModelForSequenceClassification to get all raw logits and then apply softmax ourselves \n",
    "\n",
    "normally the pipeline does the softmax and ONLY returns the highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU cores available: 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(f\"Total CPU cores available: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dask[complete] distributed --upgrade\n",
    "\n",
    "# !pip install pyarrow==10.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.0.3\n",
      "Dask version: 2023.5.0\n",
      "PyArrow version: 10.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "import pyarrow\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import duckdb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import bokeh\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Dask version:\", dask.__version__)\n",
    "print(\"PyArrow version:\", pyarrow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT model and tokenizer\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()  # Put model in evaluation mode\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"label\": \"NEUTRAL\", \"score\": 1.0, \"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "    \n",
    "    # Tokenize input text\n",
    "    # inputs = tokenizer(text[:512], return_tensors=\"pt\", truncation=True)\n",
    "    # Getting truncation warning. I'ma use tokenizer truncation instead\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradients\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # Get raw model outputs (logits)\n",
    "    probs = F.softmax(logits, dim=1)  # Apply softmax across dimension 1 (classes)\n",
    "\n",
    "    # Convert to a Python list\n",
    "    probs = probs.numpy()[0]  # Extract probabilities as a NumPy array\n",
    "\n",
    "    # Define label mapping\n",
    "    labels = [\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"]\n",
    "    sentiment_dict = dict(zip(labels, probs))\n",
    "\n",
    "    # Get the highest-probability label\n",
    "    max_label = labels[torch.argmax(logits).item()]\n",
    "    max_score = max(probs)\n",
    "\n",
    "    return {\n",
    "        \"label\": max_label,\n",
    "        \"score\": max_score,\n",
    "        \"positive\": sentiment_dict[\"POSITIVE\"],\n",
    "        \"neutral\": sentiment_dict[\"NEUTRAL\"],\n",
    "        \"negative\": sentiment_dict[\"NEGATIVE\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CANT START A CLIENT AND CLUSTER BEFORE LOADING FINBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n",
      "{'tcp://127.0.0.1:55204': 1, 'tcp://127.0.0.1:55205': 1, 'tcp://127.0.0.1:55206': 1, 'tcp://127.0.0.1:55207': 1, 'tcp://127.0.0.1:55208': 1, 'tcp://127.0.0.1:55213': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 10:48:37,316 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55204 (pid=15960) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:48:37,844 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 10:49:06,826 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55256 (pid=20052) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:49:07,399 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 10:49:27,274 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55257 (pid=11744) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:49:27,591 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 10:52:14,690 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55255 (pid=20816) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:52:15,118 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 10:52:22,007 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55260 (pid=19700) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:52:22,429 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 10:54:12,324 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55319 (pid=26148) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:54:12,684 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 10:57:05,976 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55254 (pid=11268) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 10:57:06,388 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:00:56,404 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55311 (pid=21156) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:00:56,858 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:04:03,182 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55304 (pid=13056) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:04:03,715 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60576 (pid=18920) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:04:03,752 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:04:04,178 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:04:54,102 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55363 (pid=3472) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:04:55,322 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:06:18,681 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55355 (pid=21232) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:06:19,109 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:07:10,821 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60593 (pid=24816) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:07:11,226 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:09:23,390 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60614 (pid=3508) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:09:24,372 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:09:48,095 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60634 (pid=25000) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:09:48,459 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:14:02,585 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55396 (pid=24724) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:14:03,095 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:19:28,478 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:55374 (pid=23140) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:19:29,355 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:19:39,464 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60590 (pid=7084) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:19:39,973 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:24:00,799 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60700 (pid=25712) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:24:03,230 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:24:10,807 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60658 (pid=15668) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:24:11,460 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:26:43,906 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60651 (pid=22144) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:26:44,532 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:27:18,317 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60747 (pid=17944) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:27:20,377 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:27:37,882 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60757 (pid=20848) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:27:38,424 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:32:58,090 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60771 (pid=13744) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:32:58,954 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:33:10,375 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60671 (pid=21880) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:33:11,101 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:33:36,482 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60786 (pid=19668) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:33:37,398 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:35:21,280 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60707 (pid=21728) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:35:21,985 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:35:34,827 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60605 (pid=19560) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:35:35,457 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:36:14,856 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60779 (pid=13536) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:36:15,537 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:37:36,888 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60843 (pid=24812) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:37:37,272 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:39:12,804 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60824 (pid=14840) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:39:13,363 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:40:53,831 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60880 (pid=14696) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:40:54,854 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:45:43,871 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:61001 (pid=25800) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:45:44,609 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:45:48,180 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60831 (pid=24272) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:45:52,526 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:46:46,481 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60933 (pid=3052) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:46:47,380 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:46:47,582 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60873 (pid=26232) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:46:48,248 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-03-28 11:48:57,697 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:60915 (pid=19276) exceeded 95% memory budget. Restarting...\n",
      "2025-03-28 11:48:58,586 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "# Try to avoid PyArrow\n",
    "pd.options.mode.string_storage = \"python\"\n",
    "\n",
    "# cluster = LocalCluster(n_workers=num_cores//2, threads_per_worker=1)\n",
    "cluster = LocalCluster(n_workers=6, threads_per_worker=1) # upping to full CPU cores when not using my laptop\n",
    "\n",
    "cluster.adapt(minimum=1, maximum=6)\n",
    "client = Client(cluster)\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "print(client.dashboard_link)\n",
    "print(client.ncores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = duckdb.connect(r\"..\\financial_news.db\", read_only=True)\n",
    "# # df = con.execute(\"SELECT guid, description, article_title, ticker FROM headlines.articles\").fetchdf()\n",
    "\n",
    "# # okay getting a bottle neck at pandas to ddf so ognna write as csv \n",
    "# # df.to_csv(\"articles_db.csv\", index=False)\n",
    "\n",
    "# # try writing to parquet instead\n",
    "# file_name = 'articles_db.parquet'\n",
    "# # con.execute(f\"COPY (SELECT guid, description, article_title, ticker FROM headlines.articles) TO '{file_name}' WITH (HEADER, DELIMITER ',');\")\n",
    "# # con.execute(f\"COPY (SELECT guid, description, article_title, ticker FROM headlines.articles) TO '{file_name}' (FORMAT 'parquet');\")\n",
    "# # try partitioning based on date \n",
    "\n",
    "# # will try to partition based on date later \n",
    "# output_dir = \"articles_partitioned/\"\n",
    "# con.execute(f'''\n",
    "#     COPY (\n",
    "#         SELECT \n",
    "#             guid, \n",
    "#             description, \n",
    "#             article_title, \n",
    "#             ticker, \n",
    "#             article_pubdate,\n",
    "#             YEAR(article_pubdate) AS year, \n",
    "#             MONTH(article_pubdate) AS month\n",
    "#         FROM headlines.articles\n",
    "#     ) \n",
    "#     TO '{output_dir}' \n",
    "#     (FORMAT 'parquet', PARTITION_BY (year, month));\n",
    "# ''')\n",
    "\n",
    "# con.close()\n",
    "# # df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n"
     ]
    }
   ],
   "source": [
    "# testing only\n",
    "# filtered_df = df.head(1000)\n",
    "# len(filtered_df)\n",
    "# ddf = dd.read_csv(\"articles_db.csv\", assume_missing=True, dtype={'guid': 'object', 'description': 'object', 'article_title': 'object', 'ticker': 'object'})\n",
    "# read parquet \n",
    "# ddf = dd.read_parquet(file_name, engine='pyarrow')\n",
    "\n",
    "# read from articles_partitioned output_dir \n",
    "# ddf = dd.read_parquet(r\"C:\\Users\\lucho\\OneDrive - Georgia Institute of Technology\\Practicum\\new_data\\articles\\*\\*.parquet\", engine='pyarrow')\n",
    "ddf = dd.read_csv(r\"C:\\Users\\lucho\\OneDrive - Georgia Institute of Technology\\Practicum\\new_data\\articles\\*\\*.csv\")\n",
    "# check partitions in ddf \n",
    "print(ddf.npartitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucho\\anaconda3\\envs\\cs7643-a3-nlp\\lib\\site-packages\\distributed\\client.py:3108: UserWarning: Sending large graph of size 419.98 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Enable Progress Bar\n",
    "with ProgressBar():\n",
    "    # Process title sentiment\n",
    "    ddf['finbert_title'] = ddf.map_partitions(\n",
    "        lambda df: df['article_title'].apply(classify_sentiment), meta=(\"x\", \"object\")\n",
    "    )\n",
    "    ddf['finbert_title_label'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_title'].apply(lambda x: x['label']), meta=(\"x\", \"str\")\n",
    "    )\n",
    "    ddf['finbert_title_score'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_title'].apply(lambda x: x['score']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf['finbert_title_positive'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_title'].apply(lambda x: x['positive']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf['finbert_title_neutral'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_title'].apply(lambda x: x['neutral']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf['finbert_title_negative'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_title'].apply(lambda x: x['negative']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "\n",
    "    # Process description sentiment\n",
    "    ddf['finbert_description'] = ddf.map_partitions(\n",
    "        lambda df: df['description'].apply(classify_sentiment), meta=(\"x\", \"object\")\n",
    "    )\n",
    "    ddf['finbert_description_label'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_description'].apply(lambda x: x['label']), meta=(\"x\", \"str\")\n",
    "    )\n",
    "    ddf['finbert_description_score'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_description'].apply(lambda x: x['score']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf['finbert_description_positive'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_description'].apply(lambda x: x['positive']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf['finbert_description_neutral'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_description'].apply(lambda x: x['neutral']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf['finbert_description_negative'] = ddf.map_partitions(\n",
    "        lambda df: df['finbert_description'].apply(lambda x: x['negative']), meta=(\"x\", \"float\")\n",
    "    )\n",
    "    ddf.to_csv(\"articles_with_finbert_scores.csv\")\n",
    "\n",
    "# Convert back to Pandas\n",
    "# df_final = ddf.compute()\n",
    "\n",
    "# Save results\n",
    "# df_final.to_csv(\"articles_with_all_finbert_scores.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf['finbert_description_negative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con.close()\n",
    "\n",
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-a3-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
