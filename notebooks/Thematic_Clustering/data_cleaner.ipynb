{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "import pandas as pd \n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()\n",
    "DB_PATH = Path(os.getenv(\"DB_PATH\"))\n",
    "DB_FILE = os.getenv(\"DB_FILE\")\n",
    "duckdb_path = DB_PATH / DB_FILE\n",
    "\n",
    "CSV_OUTPUT_PATH = Path(os.getenv(\"CSV_OUTPUT_PATH\"))\n",
    "CLEANED_ARTICLES_FILENAME = os.getenv(\"CLEANED_ARTICLES_FILENAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_articles(df):\n",
    "    # Keep relevant columns\n",
    "    df = df[['ticker', 'mapped_trading_date', 'article_title', 'description']].copy()\n",
    "\n",
    "    # Combine title and description\n",
    "    df['full_text'] = df['article_title'].fillna('') + \" \" + df['description'].fillna('')\n",
    "\n",
    "    # Text cleaning function\n",
    "    def clean_text(text):\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "        text = re.sub(r'[^\\w\\s$%0-9]', '', text)  # Remove punctuation but keep $, %, and numbers\n",
    "        # text = re.sub(r'[^\\w\\s$%]', '', text)  # Since we deal with data could be useful to keep $ and %\n",
    "        return text\n",
    "\n",
    "    # Apply text cleaning\n",
    "    df['clean_text'] = df['full_text'].apply(clean_text)\n",
    "    \n",
    "\n",
    "    # Lemmatization function using SpaCy\n",
    "    def lemmatize_text(text):\n",
    "        doc = nlp(text)  # Process text with SpaCy\n",
    "        return [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    # Apply lemmatization\n",
    "    df['tokens'] = df['clean_text'].apply(lemmatize_text)\n",
    "    \n",
    "    # use pipeline \n",
    "    docs = nlp.pipe(df['clean_text'], batch_size=10)  # Adjust batch_size as needed\n",
    "\n",
    "    df['tokens'] = [[token.lemma_ for token in doc if not token.is_stop] for doc in docs]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"headlines.Articles_Trading_Day\"\n",
    "dataLoader = DataLoader(duckdb_path)\n",
    "df = dataLoader.load_data(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker mapped_trading_date  \\\n",
      "0    DXC          2024-07-11   \n",
      "1    DRI          2024-07-17   \n",
      "2    DVA          2024-07-19   \n",
      "3    DRI          2024-07-22   \n",
      "4    DVA          2024-07-23   \n",
      "\n",
      "                                              tokens  \n",
      "0  [dxc, technology, report, fiscal, quarter, 202...  \n",
      "1  [darden, buy, chuy√¢s, $, 600, m, allcash, tran...  \n",
      "2  [update, davita, pay, $, 345, million, settlem...  \n",
      "3  [analyst, financial, statement, darden, restau...  \n",
      "4  [davita, healthcare, dva, lap, stock, market, ...  \n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "df_cleaned = preprocess_articles(df)\n",
    "\n",
    "# Show sample output\n",
    "print(df_cleaned[['ticker', 'mapped_trading_date', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(f'{CSV_OUTPUT_PATH}/{CLEANED_ARTICLES_FILENAME}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker                 363820\n",
       "mapped_trading_date    363820\n",
       "article_title          363820\n",
       "description            363820\n",
       "full_text              363820\n",
       "clean_text             363820\n",
       "tokens                 363820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
